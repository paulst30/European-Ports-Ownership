---
title: "Estimation"
author: "Paul Stricker"
bibliography: literature_list.bib
date: "2023-11-29"
output: 
 html_document:
      keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(patchwork)
library(ggplot2)
library(fixest)
library(did)
library(CInf)
library(readxl)
library(gt)
library(xtable)
library(extrafont)

loadfonts(device = "win")
set.seed(100)

#load data
load("port_data_TEU.RData")

port_data_TEU <- filter(port_data_TEU, aggregate==0,
                                       stat_port==1,              #filter out non-stat ports (and geographic aggregates)
                                       TEU_yrly >=20000,          #filter out small ports
                                       port_code!="DEHAM") %>%    #exclude Hamburg due to very recent treatment
             mutate(s_china = ifelse(sender_code=="CN_X_HK" | sender_code=="HK", 1, 0)) %>%
             group_by(port_code, sender_code) %>%
             mutate(pair_id=cur_group_id()) %>% ungroup() %>%
             rename(container=total_TEU)


port_data_agg <- port_data_TEU %>% mutate(origin_china = ifelse(!is.na(container) & (sender_code=="CN_X_HK" | sender_code=="HK"),container,0)) %>%
                               group_by(port, port_code, period, reporter_code) %>% 
                               summarize(container = sum(container, na.rm=T),
                                         real_gdp_reporter = mean(real_gdp_reporter),
                                         origin_china = sum(origin_china),
                                         group = max(group),
                                         group_operation = max(group_operation),
                                         ownership_china = max(ownership_china),
                                         operation = max(operation),
                                         year = max(year),
                                         quarter = max(quarter)) %>% ungroup() %>%
                              group_by(port_code) %>% 
                              mutate(port_id = cur_group_id(),
                                     mean_container = mean(container, na.rm=T)) %>% ungroup()

#exclude Rotterdam
port_data_TEU$container[port_data_TEU$port_code=="NLRTM" & between(port_data_TEU$year,2011,2020)]<-NA
port_data_agg$container[port_data_agg$port_code=="NLRTM" & between(port_data_agg$year,2011,2020)]<-NA

port_data_agg_ny <- port_data_agg %>% filter(group!=0)

port_list <- port_data_agg %>% filter(group!=0) %>% group_by(port) %>% summarize(id = mean(port_id))

port_group_list <- port_data_agg %>% filter(group!=0) %>% group_by(group) %>%
                                     summarize(ports = toString(unique(port)))
port_group_list_op <- port_data_agg %>% filter(group_operation!=0) %>% group_by(group_operation) %>%
                                     summarize(ports = toString(unique(port))) %>% 
                                     rename(group = group_operation)
port_group_list <- rbind(port_group_list, port_group_list_op)
port_group_list <- port_group_list[!duplicated(port_group_list$group),]
port_group_list$ports <- paste(port_group_list$ports,paste("(", port_group_list$group, ")", sep = ""))

# Add Control variables --------------------------------------------------------

# add terminal data to the data set
#terminal_data <- read_xlsx("port_manual_berth.xlsx")

load("berth_data.RData")
terminal_data <- berth_data
  
# add channel depth and cranes from World port index
wpi_data <- read.csv("WPI_data.csv")

# control variables
control_var <- merge(wpi_data, terminal_data, by.x="port_code",by.y="port_code", all = T) %>%
               select(port_code, 
                      year, quarter, quay_length, cranes, 
                      cranes_fixed, cranes_mobile, cranes_floating, max_lift, cargo_depth)


# merge with aggregated data
port_data_agg <- merge(port_data_agg, control_var, by.x = c("port_code", "year", "quarter"), by.y = c("port_code", "year", "quarter"), all.x = T) 

#port_data_agg$ships[port_data_agg$ships==0] <- 1

port_data_agg$quay_length[port_data_agg$quay_length==0] <- 100
port_data_agg$cranes[port_data_agg$cranes==0] <- 1

### Control variables for DID ####


controls <- c("cranes", "max_lift", "cargo_depth")
var_controls <- c("quay_length")

#controls <- c("cranes", "max_lift", "cargo_depth")
#var_controls <- c("quay_length")

```


# Baseline equation (fixed effects)

In the first attempt, a simple fixed effects model and aggregated data on container throughput is used to identify the effect of Chinese port ownership. The effect of chinese ownership is included in form of a dummy variable ($ChineseOwnership_{pt}$) that is set to one when the ownership (at least partly) transfered to a Chinese company (needs clarification).

$Thrpt_{prt}=\alpha_{p}+\theta_{rt} +ChineseOwnership_{pt}+e_{pt}$ 

Where $p$ stands for the port, $r$ for the reporting country, and $t$ for the period. In equation (1), the quarterly ($t$) container throughput ($Thrpt$) is explained by a set of port fixed-effects ($\alpha_{p}$), and reporter country-time fixed effects ($\theta_{rt}$). This specification controls for all time-invariant port-specific, and all time-invariant reporter country-specific unobserved covariates.
Second, we leverage the bilateral structure of the data, and use the variation between partner country and port over time to identify the effect of Chinese ownership on port throughput. The advantage of this approach is that we can use higher levels of fixed effects, which enable a much more precise control over which variation is used to identify the treatment effect. We proceed by estimating multiple equations with different levels of fixed effects with increasing restrictiveness:

$Thrpt_{prct}=\alpha_{p}+\beta_{c}+\gamma_{t}+ChineseOwnership_{pt}+ChineseOwnership_{pt}*ChinesePartner_{pc}+e_{prct}$ 

Where $c$ stands for the partner country, i.e. the destination/origin of the shipped container. We also include an interaction term of our treatment indicator ($ChineseOwnership_{pt}$) with the an indicator for shipments fromo and to China ($ChinesePartner_{pc}$). In equation (2), we account for all port-specific time-invariant unobserved covariates and all partner-specific unobserved covariates. That includes influencing factors like the average port size and geographic position, but also economic size of the origins and destinations of container shipments.

$Thrpt_{prct}=\alpha_{pc}+\beta_{ct}+ChineseOwnership_{pt}+ChineseOwnership_{pt}*ChinesePartner_{pc}+e_{prct}$ 

Equation (3) increases the restrictiveness of the fixed effects by replacing the port-level fixed effects with port-partner fixed effects and the partner fixed effects with partner-time fixed effects. This set of fixed effects controls for all time-invariant port-partner specfic covariates like regular shipping routes, geographic proximity and preferences. Additionally, time-varying partner country covariates, like economic up- or downswings are accounted for as well.

$Thrpt_{prct}=\alpha_{pc}+\beta_{ct}+ChineseOwnership_{pt}+ChineseOwnership_{pt}*ChineseOrigin_{pc}+e_{prct}$ 

Lastly, equation (4) adds another dimension to the fixed effects. In addition to controlling for port-partner time-invariant covariates, it also controls for reporter-time fixed effects. These encapsule all reporter-time varying covariates, like production and demand shocks in the port's country.



```{r include=FALSE}
spec1 <- feols(container ~ ownership_china  | port_code + period + reporter_code^period,
               data = port_data_agg)
spec2 <- feols(container ~ ownership_china + ownership_china:s_china  | port_code + sender + period,
               data = port_data_TEU)
spec3 <- feols(container ~ ownership_china + ownership_china:s_china | port_code^sender + sender^period,
               data = port_data_TEU)
spec4 <- feols(container ~ ownership_china + ownership_china:s_china  | port_code^sender + sender^period + reporter_code^period,
               data = port_data_TEU)




#set formatting names
setFixest_dict(c(ownership_china = "Ownership Chinese SOE",
                 s_china = "Origin China",
                 port_code = "Port",
                 period = "Period",
                 reporter_code = "Reporter",
                 sender = "Partner"))

#save table to latex 
cat(esttex(spec1, spec2, spec3, spec4,
                    depvar = FALSE,
                    style.df = style.df(depvar.title = "",
                                        fixef.title = "",
                                        fixef.suffix = "", yesNo = "yes"),
                    vcov = "twoway",
                    adjustbox = TRUE,
                    title = "Fixed effects Results",
                    label = "tab:fe_results"
                    #tex = TRUE
           ), file = file.path(getwd(),"results_tables","fe_results.tex"))

#prepare table for Markdownfile
fe_results<- etable(spec1, spec2, spec3, spec4,
                    depvar = FALSE,
                    style.df = style.df(depvar.title = "",
                                        fixef.title = "",
                                        stats.title = "",
                                        fixef.suffix = "", yesNo = "yes"),
                    vcov = "twoway")
colnames(fe_results)[1] <- "col1"

fe_results_gt <- fe_results %>%  
                  gt(rowname_col = "col1") |>
                 tab_header(title = "Fixed effects estimation results",
                            subtitle = "Dependent variable: Total throughput in thousand TEU") |>
              cols_label(
                spec1 = "Eq. 1",
                spec2 = "Eq. 2",
                spec3 = "Eq. 3",
                spec4 = "Eq. 4") |>
              tab_row_group(label = "Fixed effects:",
                            rows = c("Port", "Period", "Reporter-Period", "Partner", "Port-Partner", "Partner-Period"))  |>
              tab_row_group(label = "Diagnostics:",
                            rows = c("S.E.: Clustered", "Observations", "R2", "Within R2")) |>
              row_group_order(groups = c(NA, "Fixed effects:", "Diagnostics:")) |>
  cols_align(align = "center", columns = c("spec1", "spec2", "spec3", "spec4"))



```

```{r include=TRUE, echo=F}
fe_results_gt %>% 
  tab_options(row_group.border.bottom.color = "transparent",
              table_body.hlines.color = "transparent",
              stub.border.width = 0,
              stub.border.color = "transparent",
              row_group.padding = 0) 

        
```

While the fixed effects identification strategy presented above is a common one in the literature, many authors criticize the model for its lack of interpretable results. In particular, it is often unclear how the coefficients in fixed effects models are obtained and which units have served as comparisons to treated units, especially when the treatment timing varies between units. @Chaisemartin.2020 and @Borusyak.2022 find that the treatment effect estimated by two-way fixed effects models (as in equation (2)) is a weighted average of time-specific treatment effects with some weights potentially being negative. In extreme cases, this can cause negative coefficients although all time-specific treatment effects are positive. @GoodmanBacon.2021 point out that the estimator can be seen as a weighted average of all possible comparisons between treated, untreated, and not-yet-treated units, with the weights depending on treatment timing and the number of observations and conclude that a fixed effects set should be avoided, when the treatment effect is likely to vary over time.  

Another common issue is finding reasonable counterfactuals when interpreting the coefficients from fixed effects models. @Mummolo.2018 notes that researchers tend to present unrealistic counterfactuals when using fixed effects regression. Since fixed effect models only use a fraction of the variance to estimate the coefficients, interpreting the model with counterfactuals that are drawn from the original distribution of the data often leads to unrealistically high effects that sometimes falsely imply economically relevant effect sizes. Additionally, the major benefit of fixed effects, the ability to control for unobserved covariates, critically depends on the linear additive assumption [@Imai.2021]. In cases where the variation can be attributed to several dimensions of fixed effects, the estimator is undefined [@Kropko.2020].

In the last couple of years, there has developed a growing literature that tries to circumvent the issues attached to staggered treatment adoption. Notably, @Sun.2021 and @Callaway.2021 propose to estimate the treatment effects on the disaggregated group-time level and aggregate them later to obtain average treatment effects or event study results. In this paper, we employ a similar approach by estimating the unit-time treatment effects and aggregating them at different levels to obtain the average treatment effects on the treated. We chose to deviate from estimating group-time effects, as we only have 18 treated ports, most which are treated at a different points in time. That leaves most treatment groups with a single port and a few treatment groups with a handful of ports with no obvious common attributes. In particular, we assume that for every treated port $i$ the following parallel trend assumption holds: 

$E[Y_{i,t}(0)-Y_{i,t^*(i)}(0)|G=1,X_{i}]=E[Y_{t}(0)-Y_{t^*(i)}(0)|G=0,X]$
with $t > t^*$

where $Y_{t}(0)$ stands for the potential untreated outcome at time $t$, $G$ is an indicator variable indicating treated units, $t^*(i)$ indicates the last period before treatment of unit $i$, and $X$ is a matrix of time-invariant covariates. This assumption allows us to estimate the unit-time treatment effects on the treated: 

$ATT(i,t)=E[Y_{i,t}(1)-Y_{i,t}(0)|X_{i}]=E[Y_{i,t}(1)-Y_{i,t^*(i)}(0)|G=1,X_{i}]-E[Y_{t}(0)-Y_{t^*(i)}(0)|G=0, X]$

where $Y_{i,t}(1)$ represents the treated outcome of unit $i$. We estimate the conditional unit-time ATTs by a simple regression procedure by Heckmann 1998: We first estimate the expected outcome trend of the untreated units at each $t$, regressing the difference in untreated outcomes on the time-invariant covarites $X$. That is, for all untreated units $j$ and time $t$, we estimate:

$Y_{j,t}(0)-Y_{j,t^*}(0)=\alpha_{t}+X_{j}\beta_{t}+\eta_{j,t}$

We then use the estimated coefficients to  predict the counterfactual outcome trend of the treated units. The unit-time ATT is then given by the difference between the observed trend in the treated outcome and the counterfactual trend. Note that the coefficients are reestimated for each unit-time observation. This means that we allow for a time-varying influence of the covariates on the outcome. 

Unfortunately, the separate estimation of many treatment effects with just one treated unit causes standard inference to be invalid with analytical standard errors clustered at the unit-level being overly optimistic [@Ferman.2019]. Against this backdrop, we implement the bootstrap procedure of @Alvarez.2023, which leads to confidence intervals of the correct size in situations with a fixed number of treated units and a large number of control units. Their method also allows for correlation within units over time and corrects for a known structure of heteroscedasticity between units, which is likely in our application. The main idea is to use the control unitsâ€™ residuals of the outcome model to estimate the structural form of heteroscedasticity and the distribution of the treated units [@Conley.2011]. For this to be viable, two assumptions need to be made in addition to the regular DiD assumptions. First, the expected errors of the outcome model should be the same, regardless of the treatment status: $E[\eta_{j}|X_{j}]=E[\eta_{i}|X_{i}]=0$. This is equivalent to the parallel trend assumption above. Second, the errors of the outcome model should be represented by a known function $\eta_{j,t}=h_{i}(Z_{j}, \delta_{i})\epsilon_{j,t}$, where $h_{i}(.,.)$ is a known function, $Z_{j}$ is a set of covariates, $\delta_{i}$ is an unknown parameter, and $\epsilon_{j,t}$ is $iid$ for all $j$. @Ferman.2019 show that the variance of the errors from the outcome model can be described by a function $V(\eta_{j,t})=A+B/Z_{j}$ with $A,B>=0$ for wide range of error structures, including within-unit correlation in a panel setting. In detail, we apply the following protocol to estimate the 95 percent confidence intervals: *add algorithm table*

We track the errors of the control units when estimating the outcome model. These errors are then used to estimate the structure of heteroscedasticity between units by regressing the squared residuals on a constant and a set of control variables (in our case, their quay length). Then, the residuals are normalized by their variance estimate, and a bootstrap sample of normalized residuals is drawn at the unit level. In every bootstrap iteration, one untreated unit is drawn for each treated unit and the normalized residuals of that untreated unit are added to the bootstrap sample. Bootstrapping at the unit level ensures that the correlation structure within the bootstrapped units is persevered. All normalized residuals in the bootstrap sample are scaled by the estimated variance of the respective treated unit. Then, the confidence intervals are determined by the 95 percent quantile of the bootstrapped normalized errors. As recommended by @Alvarez.2021, we account for the multiple testing problem by reducing the bootstrap sample to the highest rescaled residuals for each parameter tested. Then, the uniform confidence interval is given by the 95 percent quantile of this reduced bootstrap sample.

To obtain the average treatment effect on each treated unit, we follow @Callaway.2021 by computing a simple average of all unit-time treatment effects for each treated unit. The 95 percent confidence intervals for each treated unit i is then given by the 95 quantile of the B averages of the rescaled residuals, respectively. Equivalently, we calculate an overall average treatment effect on the treated units by averaging all unit-time treatment effects over all units and periods. The 95 percent confidence intervals is given by the 95 percent quantile of the B averages obtained from the rescaled residuals.


# Difference in Differences

To address these shortcomings, we use recent advances in the DiD literature, and employ a staggered DiD estimator by @Callaway.2021. They formulate a unified approach to estimating average treatment effects in a DiD framework with multiple periods and varying treatment timing that avoids all above described interpretation issues. They define group-time average treatment effects, which measure the average treatment effect for a group of units that receive the treatment at the same point in time. In a later step, these group-time average treatment effects can be aggregated either by time period or group to derive an overall average treatment effect. Another advantage of their approach is that it gives the research the liberty to choose which comparison group should be used to calculate the treatment effects. That is, whether the comparison group includes only never-treated or not-yet-treated units. This translates to two parallel trend assumptions. When the comparison group is made up of never treated units:

$E[Y_{t}(0)-Y_{t-1}(0)|G=g]=E[Y_{t}(0)-Y_{t-1}(0)|C=1]$ 
with $g\leq t$ \left (6)

Where $Y_{t}(0)$ denotes the potential untreated outcome in period t, $G$ indicates the period a unit is first treated, and $C$ is an indicator that takes the value of one if a unit is never treated. Hence, the first term of the equation above denotes the difference between untreated outcomes of period t and period t-1 for units while they are treated, and the second term denotes the difference between potential outcomes of periods t and t-1 for units that are never treated. In a setting with staggered treatment, random sampling, and not treatment anticipation, the above parallel trend assumption leads the following group-time average treatment effects: 

$ATT(g,t)=E[Y_{t}(g)-Y_{t}(0)|G=g]=E[Y_{t}-Y_{g-1}|G=g]-E[Y_{t}-Y_{g-1}|C=1]$ \left (7)

Where $Y_{t}(g)$ denotes the treated outcome in period $t$, $Y_{t}$ denotes the observed outcome in period $t$. Hence, the average $ATT(g,t)$ represents the average effect of treatment in period t for units that are first treated in period g. To derive at an overall average treatment effect, we use a simple aggregation scheme as proposed by @Callaway.2021, which weights each ATT by the size of the group. 


```{r include=F, message=FALSE, warning=FALSE}

#### Estimation ot ATT with never treated as control group ####
attgt <- simple_staggered_did(yname = "container",            #outcome variable
                              tname = "period",                 #time variable
                              idname = "port_id",                    #id for units (should be port_code*sender)
                              gname = "group",                    #grouping variable for first treatment. Is zero for never treated units)
                              #xformula = c("ships"),
                              #varformula = c("ships"),
                              #control_group = "not_yet_treated",
                              data = port_data_agg)


attgt_cond <- simple_staggered_did(yname = "container",            #outcome variable
                              tname = "period",                 #time variable
                              idname = "port_id",                    #id for units (should be port_code*sender)
                              gname = "group",                    #grouping variable for first treatment. Is zero for never treated units)
                              xformula = controls,
                              varformula = var_controls,
                              #control_group = "not_yet_treated",
                              data = port_data_agg)



# putting together the results

results1 <- data.frame(Estimate = c("simple average", port_list$port[match(as.character(attgt$groupwise_treatment_effects$id), port_list$id)]),
                       ATT = c(attgt$average_treatment_effect$att,
                                   attgt$groupwise_treatment_effects$att),
                       lower = c(attgt$average_treatment_effect$att - attgt$average_treatment_effect$crit_val,
                                attgt$groupwise_treatment_effects$att - attgt$groupwise_treatment_effects$crit_val),
                       upper = c(attgt$average_treatment_effect$att + attgt$average_treatment_effect$crit_val,
                                  attgt$groupwise_treatment_effects$att + attgt$groupwise_treatment_effects$crit_val),
                       p_value = c(NA, attgt$groupwise_treatment_effects$pre_treatment_p_value))

results2 <- data.frame(Estimate = c("simple average", port_list$port[match(as.character(attgt_cond$groupwise_treatment_effects$id), port_list$id)]),
                       ATT_cond = c(attgt_cond$average_treatment_effect$att,
                                   attgt_cond$groupwise_treatment_effects$att),
                       lower_cond = c(attgt_cond$average_treatment_effect$att - attgt_cond$average_treatment_effect$crit_val,
                                attgt_cond$groupwise_treatment_effects$att - attgt_cond$groupwise_treatment_effects$crit_val),
                       upper_cond = c(attgt_cond$average_treatment_effect$att + attgt_cond$average_treatment_effect$crit_val,
                                  attgt_cond$groupwise_treatment_effects$att + attgt_cond$groupwise_treatment_effects$crit_val),
                        p_value_cond = c(NA, attgt_cond$groupwise_treatment_effects$pre_treatment_p_value))

results <- merge(results1, results2, by.x="Estimate", by.y="Estimate", all=T,  sort=F) %>%
               mutate(sig = (ATT>0 & lower>0) | (ATT<0 & upper<0),
                      sig_cond = (ATT_cond>0 & lower_cond>0) | (ATT_cond<0 & upper_cond<0),
                      pretest = (p_value < 0.05) & !is.na(p_value),
                      pretest_cond = (p_value_cond < 0.05) & !is.na(p_value_cond),
                      across(c("ATT","ATT_cond","lower","upper","lower_cond","upper_cond"), ~ format(round(.,digits=0), big.mark = ",")),

                      ATT = ifelse(sig==T, paste0(ATT, "*"), ATT),
                      ATT = ifelse(pretest==T, paste0(ATT, "^{x}"),ATT),
                      ATT_cond = ifelse(sig_cond==T, paste0(ATT_cond, "*"), ATT_cond),
                      ATT_cond = ifelse(pretest_cond==T, paste0(ATT_cond, "^{x}"),ATT_cond),
                      Conf = paste0("[",str_trim(lower),", ",str_trim(upper),"]"),
                      Conf_cond = paste0("[",str_trim(lower_cond),"; ",str_trim(upper_cond),"]"))
results <- results[c("Estimate", "ATT", "Conf", "ATT_cond", "Conf_cond")]



#### Estimate ATT with not-yet-treated control group ####
attgt_ny <- simple_staggered_did(yname = "container",            #outcome variable
                              tname = "period",                 #time variable
                              idname = "port_id",                    #id for units (should be port_code*sender)
                              gname = "group",                    #grouping variable for first treatment. Is zero for never treated units)
                              #xformula = c("ships"),
                              #varformula = c("ships"),
                              control_group = "not_yet_treated",
                              data = port_data_agg)


attgt_cond_ny <- simple_staggered_did(yname = "container",            #outcome variable
                              tname = "period",                 #time variable
                              idname = "port_id",                    #id for units (should be port_code*sender)
                              gname = "group",                    #grouping variable for first treatment. Is zero for never treated units)
                              xformula = controls,
                              varformula = var_controls,
                              control_group = "not_yet_treated",
                              data = port_data_agg)



# putting together the results

results_ny1 <- data.frame(Estimate = c("simple average", port_list$port[match(as.character(attgt_ny$groupwise_treatment_effects$id), port_list$id)]),
                       ATT_ny = c(attgt_ny$average_treatment_effect$att,
                                   attgt_ny$groupwise_treatment_effects$att),
                       lower_ny = c(attgt_ny$average_treatment_effect$att - attgt_ny$average_treatment_effect$crit_val,
                                attgt_ny$groupwise_treatment_effects$att - attgt_ny$groupwise_treatment_effects$crit_val),
                       upper_ny = c(attgt_ny$average_treatment_effect$att + attgt_ny$average_treatment_effect$crit_val,
                                  attgt_ny$groupwise_treatment_effects$att + attgt_ny$groupwise_treatment_effects$crit_val),
                       p_value_ny = c(NA, attgt_ny$groupwise_treatment_effects$pre_treatment_p_value))

results_ny2 <- data.frame(Estimate = c("simple average", port_list$port[match(as.character(attgt_cond_ny$groupwise_treatment_effects$id), port_list$id)]),
                       ATT_cond_ny = c(attgt_cond_ny$average_treatment_effect$att,
                                   attgt_cond_ny$groupwise_treatment_effects$att),
                       lower_cond_ny = c(attgt_cond_ny$average_treatment_effect$att - attgt_cond_ny$average_treatment_effect$crit_val,
                                attgt_cond_ny$groupwise_treatment_effects$att - attgt_cond_ny$groupwise_treatment_effects$crit_val),
                       upper_cond_ny = c(attgt_cond_ny$average_treatment_effect$att + attgt_cond_ny$average_treatment_effect$crit_val,
                                  attgt_cond_ny$groupwise_treatment_effects$att + attgt_cond_ny$groupwise_treatment_effects$crit_val),
                       p_value_cond_ny = c(NA, attgt_cond_ny$groupwise_treatment_effects$pre_treatment_p_value)) 

results_ny <- merge(results_ny1, results_ny2, by.x="Estimate", by.y="Estimate", all=T,  sort=F) %>%
               mutate(sig = (ATT_ny>0 & lower_ny>0) | (ATT_ny<0 & upper_ny<0),
                      sig_cond = (ATT_cond_ny>0 & lower_cond_ny>0) | (ATT_cond_ny<0 & upper_cond_ny<0),
                      pretest = (p_value_ny < 0.05) & !is.na(p_value_ny),
                      pretest_cond = (p_value_cond_ny < 0.05) & !is.na(p_value_cond_ny),
                      across(c("ATT_ny","ATT_cond_ny","lower_ny","upper_ny","lower_cond_ny","upper_cond_ny"), ~ format(round(.,digits=0), big.mark = ",")),
                      ATT_ny = ifelse(sig==T, paste0(ATT_ny, "*"), ATT_ny),
                      ATT_ny = ifelse(pretest==T, paste0(ATT_ny, "^{x}"),ATT_ny),
                      ATT_cond_ny = ifelse(sig_cond==T, paste0(ATT_cond_ny, "*"), ATT_cond_ny),
                      ATT_cond_ny = ifelse(pretest_cond==T, paste0(ATT_cond_ny, "^{x}"),ATT_cond_ny),
                      Conf_ny = paste0("[",str_trim(lower_ny),", ",str_trim(upper_ny),"]"),
                      Conf_cond_ny = paste0("[",str_trim(lower_cond_ny),"; ",str_trim(upper_cond_ny),"]"))
results_ny <- results_ny[c("Estimate", "ATT_cond_ny", "Conf_cond_ny")]

results <- merge(results, results_ny, by.x="Estimate", by.y="Estimate", sort=F)


```

```{r include=F}
# generate a Latex table

results_final <- rbind(results[1,],c("by group", rep("", ncol(results)-1)) ,results[2:19,]) 

# Insert multirow cell into the appropriate position in the LaTeX code
addtorow <- list()
addtorow$pos <- list(nrow(results_final),1)
addtorow$command <- c("[2ex] \\hline \\hline \\multicolumn{7}{l}{\\shortstack[l]{Note: Stars indicate that the uniform confidence interval does not include zero.\\\\ Superscript x indicates that we can reject the null of equal average pseudo treatment effects between treated and untreated.}}", 
                      "[1ex]")

# Modify the LaTeX code
latex_code <- print.xtable(xtable(results_final, caption = "Aggregation of group time treatment effects"),
                           label = "tab:did_results",
                           caption.placement = "top",
                           include.rownames = FALSE,
                           add.to.row = addtorow,
                           hline.after = c(-1,-1,0, 2),
                           size = "\\begin{adjustbox}{max width=\\textwidth}")

latex_code <- gsub("Estimate & ATT & Conf & ATT\\\\_cond & Conf\\\\_cond & ATT\\\\_cond\\\\_ny & Conf\\\\_cond\\\\_ny","Control group: & \\\\multicolumn{4}{c}{Never treated} & \\\\multicolumn{2}{c}{Not yet treated} \\\\\\\\\n \\\\cmidrule(lr){2-5} \\\\cmidrule(lr){6-7}  PTA & Uncond. & 95\\\\% CI & Cond. & 95\\\\% CI & Cond. & 95\\\\% CI ", latex_code)

latex_code <- gsub("\\\\end\\{tabular\\}", "\\\\end{tabular} \n \\\\end{adjustbox} \\\\label{tab:did_results}", latex_code)
latex_code <- gsub("by group", "\\\\emph{by group}", latex_code)
latex_code <- gsub("lllllll", "lcccccc", latex_code)
latex_code <- gsub("\\\\verb\\|\\^\\|\\\\\\{x\\\\\\}", "\\\\textsuperscript{x}", latex_code)

# Save modified LaTeX code to a .tex file
cat(latex_code, file = file.path(getwd(), "results_tables", "did_results.tex"))



# generating a gt table
results_gt <- gt(results, rowname_col = "Estimate") |>
              tab_header(
                title = "Aggregation of group time treatment effects",
                subtitle = "Dependent variable: Total throughput in thousand TEU") |>
              cols_label(
                ATT="unconditional",
                ATT_cond="conditional",
                ATT_cond_ny="conditional",
                Conf="95% CI",
                Conf_cond="95% CI",
                Conf_cond_ny="95% CI"
              ) |>
              tab_spanner(label = "Never treated",
                          columns = c("ATT", "Conf", "ATT_cond", "Conf_cond")) |>
              tab_spanner(label = "Not yet treated",
                          columns = c("ATT_cond_ny", "Conf_cond_ny")) |>
              tab_row_group(label = "by group:",
                            rows = c(2:19)) |>
              row_group_order(groups = c(NA,"by group:")) |>
              sub_missing(columns = everything(),
                          rows = everything(),
                          missing_text = "") |>
              tab_footnote(footnote = "Stars indicate that the confidence interval does not include zero.") |>
              tab_options(stub.border.width = 0,
                          table_body.hlines.width = 0
              )


```

```{r include=FALSE}

# generate latex table for presentation

results_presentation <- results_final[, c("Estimate", "ATT", "ATT_cond", "ATT_cond_ny")]

# Insert multirow cell into the appropriate position in the LaTeX code
addtorow <- list()
addtorow$pos <- list(nrow(results_presentation),1)
addtorow$command <- c("[2ex] \\hline \\hline \\multicolumn{7}{l}{\\shortstack[l]{Note: Stars indicate that the uniform confidence interval does not include zero.\\\\ Superscript x indicates that we can reject the null of equal average pseudo treatment effects between treated and untreated.}}", 
                      "[1ex]")

# Modify the LaTeX code
latex_code <- print.xtable(xtable(results_presentation,
                                  #caption = "Aggregation of group time treatment effects"
                                  ),
                           label = "tab:did_results",
                           caption.placement = "top",
                           include.rownames = FALSE,
                           add.to.row = addtorow,
                           hline.after = c(-1,-1,0, 2),
                           size = "\\begin{adjustbox}{max width=\\textwidth}")

latex_code <- gsub("Estimate & ATT & ATT\\\\_cond & ATT\\\\_cond\\\\_ny","Control group: & \\\\multicolumn{2}{c}{Never treated} & \\\\multicolumn{1}{c}{Not yet treated} \\\\\\\\\n \\\\cmidrule(lr){2-3} \\\\cmidrule(lr){4-4}  PTA & Uncond. &  Cond. & Cond. ", latex_code)

latex_code <- gsub("\\\\end\\{tabular\\}", "\\\\end{tabular} \n \\\\end{adjustbox} \\\\label{tab:did_results}", latex_code)
latex_code <- gsub("by group", "\\\\emph{by group}", latex_code)
latex_code <- gsub("llll", "lccc", latex_code)
latex_code <- gsub("\\\\verb\\|\\^\\|\\\\\\{x\\\\\\}", "\\\\textsuperscript{x}", latex_code)

# latex_code <- gsub("\\\\end\\{tabular\\}", "\\\\end{tabular} \n \\\\end{adjustbox} \\\\label{tab:did_results_presentation}
# \\\\begin{minipage}{15cm} \\\\\\\\
# \\\\tiny Note: Stars indicate that the uniform confidence interval does not include zero. Superscript x indicates that we can reject the null of equal average pseudo treatment effects between treated and untreated. \\\\\\\\
# \\\\end{minipage}", latex_code)

# Save modified LaTeX code to a .tex file
cat(latex_code, file = file.path(getwd(), "results_tables_presentation", "did_results_presentation.tex"))


```


```{r include=TRUE, echo=FALSE}
results_gt

```


One potential issue, that above DiD model may have is endogeneity. In particular, ports may be selected into treatment based on their throughput in the past. If that is the case, untreated units do not pose a credible comparison group to estimate treatment effects. To alleviate those concerns, we reestimate the treatment effects adding the not yet treated observations as the comparison group. Following @Callaway.2021, the underlying parallel trend assumption is then: 

$E[Y_{t}-Y_{t-1}|G=g]=E[Y_{t}-Y_{t-1}|D_{t}=0, G\neq g]$ with $g\leq t$ \left (8)

Where $D_{t}$ is an binary variable indicating whether a unit is treated in period t. The new parallel trend assumption then leads to the following group-time average treatment effects:

$ATT(g,t)=E[Y_{t}(g)-Y_{t}(0)|G=g]=E[Y_{t}-Y_{g-1}|G=g]-E[Y_{t}-Y_{g-1}|D_{t}=0, G\neq g]$ \left (9)

Hence $ATT(g,t)$ represents the average treatment effect of group $G$ in period $t$ in comparison to not yet treated units (and untreated units). 





# Parallel trend assumption
## Event study
For the DiD framework to deliver unbiased results, the parallel trend assumptions needs to hold. While it is not possible to test this assumption directly, we conduct a few test to validate whether the pre-treatment trends run parallel or not. The following graph displays and event study type aggregation of the group-time average treatment effects calculated above. The aggregated average treatment effects before treatment (red) are all around zero, indicating that parallel trends holds in the pre-treatment period. The graphs clearly indicate a persistent positive treatment effect after the treatment. The point-wise estimates are only significant in a couple of periods, which is due to the fact that some ports experience a high positive treatment effect while others do not. In particular *insert portnames* show consistently higher throughputs after treatment than the control group. 

```{r include=TRUE, message=FALSE, echo=FALSE, warning=FALSE, fig.dim = c(8, 14)}
# ggdid(agg_es) + scale_x_continuous(breaks = seq(-80, 80, 10)) + labs(title = "Average Effect by Length of Exposure of Ports under unconditional PTA")
# ggdid(agg_es_cond) + scale_x_continuous(breaks = seq(-80, 80, 10)) + labs(title = "Average Effect by Length of Exposure of Ports under conditional PTA")


#manually putting together eventstudy graph 
graph_results <- attgt_cond$grouptime_treatment_effects %>%
                  mutate(treatment = ifelse(t < g, "pre", "post"),
                         ymin=att-uniform_crit_val,
                         ymax=att+uniform_crit_val)

# arrange ordering according to port size
graph_results$port <- port_list$port[match(graph_results$id, port_list$id)]

factor_level <- c("Rotterdam", "Antwerpen", "Valencia", "Piraeus", "Barcelona", "Le Havre","Ambarli", "Genova", "Marseille", "Zeebrugge", "Bilbao", "Gdynia", "Thessaloniki", "Dunkerque", "Nantes Saint Nazaire", "Moerdijk", "Amsterdam", "Marsaxlokk")

graph_results$port <- factor(graph_results$port, levels=factor_level)


ggplot(graph_results, aes(x = t, y = att/1000)) + 
  geom_point(aes(shape = treatment ),fill= "white", size = 1.2) +
  geom_ribbon(aes(ymin = ymin/1000, ymax = ymax/1000), fill = "lightgrey", alpha = 0.3) +
  facet_wrap(~port, ncol = 2, scales = "free_y") +
  labs(x = "Period", y = "TEU (millions)", caption = "Note: Uniform confidence interval is based on bootstrapped errors.") +
  theme_minimal() +
  theme(panel.background = element_blank(),
        strip.text = element_text(hjust = 0, size=12),
        text = element_text(size=10, family="LM Roman 10"),
        legend.position = "bottom",
        legend.title = element_blank(),
        plot.caption = element_text(hjust = 0)) +
  scale_shape_manual(values = c(19,1))

ggsave(width=10, height=15, filename = "ATT_graph.pdf", path = file.path(getwd(), "figures"))
  


```




```{r include=FALSE, warning=FALSE}
## Placebo test
# placebo_data <- port_data_agg %>% filter(group==0)
# 
# placebo_atts <- list()
# for (j in 1:100) {
# fake_treated <- slice_sample(as.data.frame(unique(placebo_data$port_id)),n=15,replace = F)
# colnames(fake_treated)[1] <- "port_id"
# 
# for (i in 1:nrow(fake_treated)) {
#   sampled_period <- placebo_data %>%
#     filter(port_id == fake_treated$port_id[i] & !is.na(container)) %>%
#     slice_sample(n = 1) %>%
#     pull(period)  # Extract the sampled period value
# 
#   fake_treated$fake_group[i] <- sampled_period
# }
# 
# placebo_data$fake_group  <- fake_treated$fake_group[match(placebo_data$port_id, fake_treated$port_id)]
# placebo_data$fake_group[is.na(placebo_data$fake_group)] <- 0
# placebo_data$fake_group <- as.numeric(placebo_data$fake_group)
# 
# placebo_attgt <- att_gt(yname = "container",            #outcome variable
#                 tname = "period",                 #time variable
#                 idname = "port_id",                    #id for units (should be port_code*sender)
#                 gname = "fake_group",                    #grouping variable for first treatment. Is zero for never treated units
#                 #xformla = ~X,                  #for potential covariates
#                 #control_group="notyettreated",  #use not yet treated units as control group in addition to never treated units
#                 allow_unbalanced_panel = TRUE,  #allows he use of unbalanced panel data. Increases computation time.
#                 #est_method = "reg",             #indicates which estimation method should be used ("ipw", inverse probability weighting or "reg" for regression)
#                 data = placebo_data)
# 
# placebo_agg_simple <- aggte(placebo_attgt, type = "simple", na.rm=T)
# 
# placebo_atts[j] <- placebo_agg_simple$overall.att
# }
# 
# placebo_atts_df <- as.data.frame(do.call(rbind,placebo_atts))
# 
# p_value <- (sum(placebo_atts_df$V1>agg_simple[[1]]) + sum(placebo_atts_df$V1<(2*mean(placebo_atts_df$V1)-agg_simple[[1]])))/100

```

<!-- Due to the small number of treated ports, there exists the possibility that the treated ports are just coincidentally experiencing an increase in the throughput after treatment. To alleviate these concerns, we conduct a placebo test testing the sharp null of an average treatment effect of zero @Young.2019. We exclude all treated ports from the data and randomly assign `r n_distinct(port_data_agg$port[port_data_agg$ownership_china==1])` port to be treated at a random point in time and calculate the simple average treatment effect. Repeating this process for 100 times yields the empirical distribution of treatment effects depicted in the bar chart below. As expected, the distribution is centered around zero, indicating that there is no consistent average treatment effect, when the treatment is assigned randomly. The observed treatment effect of the actual treated ports (vertical line) clearly lies at the right end of the distribution. If the true treatment effect was in fact zero and the observed treatment effect was only due to a coincidental lucky pick of ports and time, that probability of the observed treatment to occur effect would be p_value*100 percent. -->

```{r echo=FALSE, message=FALSE}
# 
# ggplot(data = placebo_atts_df) + geom_histogram(aes(x=V1), stat = "bin") +
#                                  geom_vline(xintercept = agg_simple[[1]]) +
#                                  xlab("Simple average treatment effect") +
#                                  labs(title = "Average Treatment Effects of Placebo Treatments",caption = "Vertical line represents the observed treatment effect.")

```




```{r include=FALSE, warning=FALSE}

# Placebo test
# placebo_data <- port_data_agg %>% filter(group==0)
# 
# placebo_atts_share <- list()
# for (j in 1:100) {
# fake_treated <- slice_sample(as.data.frame(unique(placebo_data$port_id)),n=15,replace = F)
# colnames(fake_treated)[1] <- "port_id"
# 
# for (i in 1:nrow(fake_treated)) {
#   sampled_period <- placebo_data %>%
#     filter(port_id == fake_treated$port_id[i] & !is.na(container)) %>%
#     slice_sample(n = 1) %>%
#     pull(period)  # Extract the sampled period value
# 
#   fake_treated$fake_group[i] <- sampled_period
# }
# 
# placebo_data$fake_group  <- fake_treated$fake_group[match(placebo_data$port_id, fake_treated$port_id)]
# placebo_data$fake_group[is.na(placebo_data$fake_group)] <- 0
# placebo_data$fake_group <- as.numeric(placebo_data$fake_group)
# 
# placebo_attgt <- att_gt(yname = "share_china",            #outcome variable
#                 tname = "period",                 #time variable
#                 idname = "port_id",                    #id for units (should be port_code*sender)
#                 gname = "fake_group",                    #grouping variable for first treatment. Is zero for never treated units
#                 #xformla = ~X,                  #for potential covariates
#                 #control_group="notyettreated",  #use not yet treated units as control group in addition to never treated units
#                 allow_unbalanced_panel = TRUE,  #allows he use of unbalanced panel data. Increases computation time.
#                 #est_method = "reg",             #indicates which estimation method should be used ("ipw", inverse probability weighting or "reg" for regression)
#                 data = placebo_data)
# 
# placebo_agg_simple <- aggte(placebo_attgt, type = "simple", na.rm=T)
# 
# placebo_atts[j] <- placebo_agg_simple$overall.att
# }
# 
# placebo_atts_share_df <- as.data.frame(do.call(rbind,placebo_atts))
# 
# p_value_share <- (sum(placebo_atts_df$V1>agg_simple_share[[1]]) + sum(placebo_atts_df$V1<(2*mean(placebo_atts_df$V1)-agg_simple_share[[1]])))/100
```

```{r include=T, echo=F}
# ggplot(data = placebo_atts_share_df) + geom_histogram(aes(x=V1), stat = "bin") +
#                                  geom_vline(xintercept = agg_simple_share[[1]]) +
#                                  xlab("Simple average treatment effect") +
#                                  labs(title = "Average Treatment Effects of Placebo Treatments",caption = "Vertical line represents the observed treatment effect.")

```


# References

